{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1932af31",
   "metadata": {},
   "source": [
    "# PaddleOCR Text Extraction from Videos (Google Colab)\n",
    "\n",
    "This notebook extracts text from all videos in a GitHub repository using PaddleOCR with GPU support, saves results to a CSV, and displays logs for each video processed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0759689",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "Install PaddleOCR, OpenCV, and all required packages. Ensure GPU support is enabled for PaddleOCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f412a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PaddleOCR and dependencies (with GPU support)\n",
    "# Use the latest compatible paddlepaddle-gpu version available for your Python and CUDA version\n",
    "!pip install -q \"paddlepaddle-gpu==2.6.2\" \"paddleocr==3.3.1\" \"opencv-python-headless\" \"numpy>=1.23,<2.1\"\n",
    "import os\n",
    "import paddle\n",
    "# Check GPU availability\n",
    "print('PaddlePaddle GPU available:', paddle.is_compiled_with_cuda())\n",
    "if paddle.is_compiled_with_cuda():\n",
    "    print('Paddle device:', paddle.device.get_device())\n",
    "else:\n",
    "    print('GPU not available or PaddlePaddle not installed with GPU support.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12db10b3",
   "metadata": {},
   "source": [
    "## 2. Clone GitHub Repository and Set Up Paths\n",
    "Clone the repository containing the videos and set up the paths for processing and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa73d433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (if not already cloned)\n",
    "import os\n",
    "if not os.path.exists('text.extraction.paddle.ocr'):\n",
    "    !git clone https://github.com/DexterMorganAlpha/text.extraction.paddle.ocr.git\n",
    "\n",
    "# Set up paths\n",
    "REPO_PATH = 'text.extraction.paddle.ocr'\n",
    "VIDEOS_PATH = os.path.join(REPO_PATH, 'VIDEOS')\n",
    "OUTPUT_CSV = os.path.join(REPO_PATH, 'extracted_texts.csv')\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(REPO_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee45a7d",
   "metadata": {},
   "source": [
    "## 3. Import Required Libraries\n",
    "Import all necessary libraries for video processing, OCR, and CSV handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78dd9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import logging\n",
    "from paddleocr import PaddleOCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5eb439",
   "metadata": {},
   "source": [
    "## 4. Initialize PaddleOCR with GPU Support\n",
    "Set up the PaddleOCR object to use GPU and English language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dca946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PaddleOCR with GPU support and English language\n",
    "# PaddleOCR will use GPU if paddlepaddle-gpu is installed and CUDA is available\n",
    "ocr = PaddleOCR(\n",
    "    use_angle_cls=True,\n",
    "    lang='en'\n",
    "    # Do not pass use_gpu, gpu, or use_textline_orientation for PaddleOCR 3.3.1 + paddlepaddle-gpu 2.6.2\n",
    "    # GPU/CPU is auto-detected by PaddleOCR based on installed paddlepaddle-gpu\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bb0969",
   "metadata": {},
   "source": [
    "## 5. Define Helper Functions\n",
    "Define functions for extracting text from video frames, filtering, saving to CSV, and sorting the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed70d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reel_number(filename):\n",
    "    import re\n",
    "    match = re.search(r\"Video_(\\d+)\", filename)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "def sort_csv(csv_file_path):\n",
    "    if not os.path.exists(csv_file_path):\n",
    "        print(f\"CSV file {csv_file_path} does not exist. Skipping sorting.\")\n",
    "        return\n",
    "    with open(csv_file_path, mode='r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        sorted_data = sorted(reader, key=lambda row: int(row['Reel Number']))\n",
    "    with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=['Reel Number', 'Text'])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(sorted_data)\n",
    "\n",
    "def save_text_to_csv(csv_file_path, reel_number, extracted_text):\n",
    "    file_exists = os.path.exists(csv_file_path)\n",
    "    with open(csv_file_path, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        if not file_exists:\n",
    "            writer.writerow(['Reel Number', 'Text'])\n",
    "        writer.writerow([reel_number, extracted_text])\n",
    "        print(f\"Saved text for reel {reel_number} to {csv_file_path}\")\n",
    "\n",
    "def extract_text_from_white_area(frame):\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    min_x, max_x = 0, frame_width\n",
    "    min_y, max_y = 0, frame_height\n",
    "    white_area = frame[min_y:max_y, min_x:max_x]\n",
    "    result = ocr.predict(white_area)\n",
    "    white_area_text = \"\"\n",
    "    if result and len(result) > 0:\n",
    "        for res in result:\n",
    "            if isinstance(res, dict) or hasattr(res, '__getitem__'):\n",
    "                rec_texts = res.get('rec_texts', []) if isinstance(res, dict) else getattr(res, 'rec_texts', [])\n",
    "                rec_scores = res.get('rec_scores', []) if isinstance(res, dict) else getattr(res, 'rec_scores', [])\n",
    "                for text, score in zip(rec_texts, rec_scores):\n",
    "                    if score > 0.5:\n",
    "                        white_area_text += text + \" \"\n",
    "    return white_area_text.strip()\n",
    "\n",
    "def filter_text(complete_text, unnecessary_words=None, unnecessary_patterns=None, remove_before=None, remove_after=None, fallback_text=\"\"):\n",
    "    filtered_text = complete_text    \n",
    "    filtered_text = re.sub(r'[^\\w\\s]', '', filtered_text)\n",
    "    if unnecessary_words:\n",
    "        words = filtered_text.split()\n",
    "        filtered_text = \" \".join(word for word in words if word not in unnecessary_words)\n",
    "    if unnecessary_patterns:\n",
    "        lines = filtered_text.splitlines()\n",
    "        filtered_text = \"\\n\".join(line for line in lines if not any(re.search(pattern, line) for pattern in unnecessary_patterns))\n",
    "    if remove_before:\n",
    "        for word in remove_before:\n",
    "            match = re.search(rf'\\b{word}\\b', filtered_text, re.IGNORECASE)\n",
    "            if match:\n",
    "                filtered_text = filtered_text[match.start():]\n",
    "                break\n",
    "    if remove_after:\n",
    "        for word in remove_after:\n",
    "            match = re.search(rf'\\b{word}\\b', filtered_text, re.IGNORECASE)\n",
    "            if match:\n",
    "                filtered_text = filtered_text[:match.end()]\n",
    "                break\n",
    "    if not filtered_text.strip():\n",
    "        filtered_text = fallback_text\n",
    "    return filtered_text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437b6414",
   "metadata": {},
   "source": [
    "## 6. Process All Videos and Save Results\n",
    "Iterate through all video files, extract text, log the reel number and text, and save to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove existing CSV if present\n",
    "if os.path.exists(OUTPUT_CSV):\n",
    "    os.remove(OUTPUT_CSV)\n",
    "\n",
    "unnecessary_words = [\"W\", \"WA\"]\n",
    "unnecessary_patterns = []\n",
    "remove_before = []\n",
    "remove_after = []\n",
    "custom_text = \"If only there is a page dedicated\"\n",
    "\n",
    "video_files = [f for f in os.listdir(VIDEOS_PATH) if f.endswith('.mp4') and f.startswith('Video')]\n",
    "video_files.sort(key=lambda x: get_reel_number(x) or 0)\n",
    "\n",
    "for filename in video_files:\n",
    "    reel_number = get_reel_number(filename)\n",
    "    input_video_path = os.path.join(VIDEOS_PATH, filename)\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Failed to open video file: {input_video_path}\")\n",
    "        continue\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f\"Failed to read the first frame of video: {input_video_path}\")\n",
    "        cap.release()\n",
    "        continue\n",
    "    white_area_text = extract_text_from_white_area(frame)\n",
    "    filtered_text = filter_text(white_area_text, unnecessary_words, unnecessary_patterns, remove_before, remove_after, custom_text)\n",
    "    print(f\"Reel {reel_number}: {filtered_text}\")\n",
    "    save_text_to_csv(OUTPUT_CSV, reel_number, filtered_text)\n",
    "    cap.release()\n",
    "\n",
    "sort_csv(OUTPUT_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdbb575",
   "metadata": {},
   "source": [
    "## 7. Display Extracted Texts from CSV\n",
    "Read and display the extracted texts for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be894094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "if os.path.exists(OUTPUT_CSV):\n",
    "    df = pd.read_csv(OUTPUT_CSV)\n",
    "    display(df)\n",
    "else:\n",
    "    print(f\"CSV file {OUTPUT_CSV} not found.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
